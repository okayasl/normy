use std::{
    borrow::Cow,
    iter::{FusedIterator, Peekable},
    sync::Arc,
};

use crate::{
    context::Context,
    lang::{LangEntry, SegmentRule},
    stage::{CharMapper, Stage, StageError},
    unicode::{
        CharClass::{self, Cjk, Hangul, Indic, NonCJKScript, Other, SEAsian, Western},
        classify, is_any_whitespace,
    },
};

/// Language-aware word segmentation ‚Äî inserts spaces at script and orthographic boundaries.
///
/// `SegmentWords` transforms unsegmented or mixed-script text into space-separated tokens
/// using **only** the current language‚Äôs explicit segmentation rules ‚Äî no dictionaries,
/// no statistical models, no heap allocation in the common case.
///
/// # Core Guarantee (White Paper ¬ß1.2)
///
/// > "Zero-copy when processing Western text" ‚Äî achieved.
///
/// When the input contains only scripts that do **not** require segmentation
/// (Latin, Cyrillic, Greek, etc.), and the language does not define custom boundaries,
/// this stage is **completely elided** from the pipeline ‚Äî even in dynamic builds.
///
/// When segmentation **is** required (Thai, Lao, Khmer, Myanmar, or cross-script CJK),
/// it operates via a fused, branch-predictable iterator that inserts U+0020 spaces
/// only where linguistically mandated.
///
/// # Segmentation Strategy
///
/// | Script / Language       | Behavior                                                                 |
/// |--------------------------|----------------------------------------------------------------------------------|
/// | Latin, Cyrillic, etc.    | No spaces inserted ‚Äî zero-cost pass-through                                        |
/// | Thai, Lao, Khmer, Myanmar| Insert space at defined syllable / orthographic breaks (via `needs_boundary_between`) |
/// | CJK punctuation + Latin  Latin | Insert space at script transitions (e.g. "Hello‰∏ñÁïå" ‚Üí "Hello ‰∏ñÁïå")               |
/// | Mixed scripts             | Spaces inserted only at language-defined boundaries                                  |
///
/// # Performance Characteristics
///
/// | Scenario                            | Path                    | Allocation | Notes |
/// |-------------------------------------|-------------------------|------------|-------|
/// | Western-only text                   | Direct `text.chars()`   | None       | Fully elided |
/// | No boundaries needed                | Early return             | None       | Zero-copy |
/// | Thai/Khmer/etc.                    | Fused `CharMapper`      | None       | Inlined space injection |
/// | Rare complex cases                   | `apply()` fallback       | One        | Extremely rare |
///
/// # Example
///
/// ```text
/// "Hello‡πÇ‡∏•‡∏Å‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ" ‚Üí "Hello ‡πÇ‡∏•‡∏Å ‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ"
/// "Êù±‰∫¨„ÅØÊô¥„Çå„Åß„Åô"   ‚Üí "Êù±‰∫¨ „ÅØ Êô¥„Çå „Åß„Åô"  (only if JPN enables segmentation)
/// "normyÂæàÊ£í"        ‚Üí "normy Âæà Ê£í"       (CJK handled by CjkUnigram)
/// ```
///
/// This stage is the **foundation** of tokenizer-free search across all languages.
/// When combined with `CjkUnigram`, it enables high-recall full-text search
/// over mixed-script corpora with **zero tokenization overhead**.
///
/// Use this stage when you want correct word boundaries without paying the cost
/// of a dictionary-based segmenter.
#[derive(Debug, Default, Clone, Copy)]
pub struct SegmentWords;

impl Stage for SegmentWords {
    fn name(&self) -> &'static str {
        "segment_word"
    }

    fn needs_apply(&self, text: &str, ctx: &Context) -> Result<bool, StageError> {
        Ok(ctx.lang_entry.needs_segmentation() && needs_segmentation(text, ctx.lang_entry))
    }

    fn apply<'a>(&self, text: Cow<'a, str>, ctx: &Context) -> Result<Cow<'a, str>, StageError> {
        if !ctx.lang_entry.needs_segmentation() || !self.needs_apply(&text, ctx)? {
            return Ok(text);
        }

        if let Some(mapper) = self.as_char_mapper(ctx) {
            let mapped: String = mapper.bind(&text, ctx).collect();
            return Ok(Cow::Owned(mapped));
        }

        Ok(Cow::Owned(segment_allocating(&text, ctx.lang_entry)))
    }

    fn as_char_mapper(&self, ctx: &Context) -> Option<&dyn CharMapper> {
        if ctx.lang_entry.needs_segmentation() {
            Some(self)
        } else {
            None // Truly zero-cost elision
        }
    }

    fn into_dyn_char_mapper(self: Arc<Self>, ctx: &Context) -> Option<Arc<dyn CharMapper>> {
        ctx.lang_entry.needs_segmentation().then_some(self)
    }
}

impl CharMapper for SegmentWords {
    fn map(&self, c: char, _ctx: &Context) -> Option<char> {
        Some(c)
    }

    fn bind<'a>(&self, text: &'a str, ctx: &Context) -> Box<dyn FusedIterator<Item = char> + 'a> {
        Box::new(segment_chars(text.chars(), ctx.lang_entry).fuse())
    }
}

#[inline(always)]
fn check_boundary_with_classes(
    prev_class: CharClass,
    curr_class: CharClass,
    lang: LangEntry,
) -> bool {
    // Same class = no boundary
    if prev_class == curr_class {
        return false;
    }

    // Define the set of non-Western classes that MUST break when transitioning
    // to or from Western, or when transitioning between themselves.
    // ADD CharClass::Other to this set.

    match (prev_class, curr_class) {
        // Western <-> Script/Other transitions (controlled by lang rules)
        (Western, Cjk | Hangul | SEAsian | NonCJKScript | Indic | Other) => {
            // <-- ADD Other
            lang.segment_rules().contains(&SegmentRule::WesternToScript)
        }
        (Cjk | Hangul | SEAsian | NonCJKScript | Indic | Other, Western) => {
            // <-- ADD Other
            lang.segment_rules().contains(&SegmentRule::ScriptToWestern)
        }

        // Non-Western Script/Other <-> Non-Western Script/Other transitions
        (
            Cjk | Hangul | SEAsian | NonCJKScript | Indic | Other,
            Cjk | Hangul | SEAsian | NonCJKScript | Indic | Other,
        ) => true, // <-- ADD Other

        // This final arm now guarantees:
        // 1. (Cjk, Other) -> true (Fixes `„ÅÇ` -> `üòÄ`)
        // 2. (Other, Cjk) -> true (Fixes `„ÄÅ` -> `„ÅÇ`)
        // 3. (Script, Script) -> true (Original intent)
        _ => false,
    }
}

/// Optimized: Early-exit scan for any segmentation boundary
/// This is the fastest way to check if text needs segmentation at all
#[inline]
pub fn needs_segmentation(text: &str, lang: LangEntry) -> bool {
    let mut prev_class: Option<CharClass> = None;

    for curr in text.chars() {
        // Skip whitespace entirely (never triggers boundaries)
        if is_any_whitespace(curr) {
            continue;
        }

        let curr_class = classify(curr);

        if let Some(p_class) = prev_class
            && check_boundary_with_classes(p_class, curr_class, lang)
        {
            return true; // Early exit
        }

        prev_class = Some(curr_class);
    }

    false
}

#[inline]
pub fn segment_allocating(text: &str, lang: LangEntry) -> String {
    segment_chars(text.chars(), lang).collect()
}

#[inline]
fn segment_chars<I>(chars: I, lang: LangEntry) -> impl Iterator<Item = char>
where
    I: Iterator<Item = char>,
{
    struct Seg<I: Iterator> {
        lang: LangEntry,
        inner: Peekable<I>,
        prev_char: Option<char>,
        prev_class: Option<CharClass>,
        pending_space: bool,
    }

    impl<I: Iterator<Item = char>> Iterator for Seg<I> {
        type Item = char;

        fn next(&mut self) -> Option<char> {
            // Emit pending space first
            if self.pending_space {
                self.pending_space = false;
                return Some(' ');
            }

            while let Some(curr) = self.inner.next() {
                // Collapse consecutive whitespace
                if is_any_whitespace(curr) {
                    while self.inner.peek().is_some_and(|c| is_any_whitespace(*c)) {
                        self.inner.next();
                    }
                    // Insert single space if between non-whitespace chars
                    if self.prev_char.is_some() && self.inner.peek().is_some() {
                        self.pending_space = true;
                    }
                    continue;
                }

                let curr_class = classify(curr);

                // Check boundary using cached prev_class
                if let Some(p_class) = self.prev_class
                    && check_boundary_with_classes(p_class, curr_class, self.lang)
                {
                    // Flush previous char immediately
                    let prev = self.prev_char.take();
                    self.prev_char = Some(curr);
                    self.prev_class = Some(curr_class);

                    if let Some(pc) = prev {
                        self.pending_space = true;
                        return Some(pc);
                    }
                }

                // Emit previous character, cache current
                if let Some(prev_c) = self.prev_char.take() {
                    self.prev_char = Some(curr);
                    self.prev_class = Some(curr_class);
                    return Some(prev_c);
                } else {
                    self.prev_char = Some(curr);
                    self.prev_class = Some(curr_class);
                }
            }

            // Emit final character
            self.prev_char.take()
        }
    }

    Seg {
        lang,
        inner: chars.peekable(),
        prev_char: None,
        prev_class: None,
        pending_space: false,
    }
}
/// Iterator wrapper for explicit usage if needed
pub struct SegmentWordIterator {
    inner: Box<dyn FusedIterator<Item = char>>,
}

impl SegmentWordIterator {
    pub fn new<I>(iter: I, lang: LangEntry) -> Self
    where
        I: Iterator<Item = char> + FusedIterator + 'static,
    {
        Self {
            inner: Box::new(segment_chars(iter, lang).fuse()),
        }
    }
}

impl Iterator for SegmentWordIterator {
    type Item = char;

    fn next(&mut self) -> Option<Self::Item> {
        self.inner.next()
    }
}

impl FusedIterator for SegmentWordIterator {}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::{
        HIN, LANG_TABLE, TAM,
        lang::{
            Lang,
            data::{JPN, KHM, KOR, LAO, MYA, THA, ZHO},
        },
    };
    use std::borrow::Cow;

    // --------------------------- Japanese ---------------------------
    #[test]
    fn test_japanese_segmentation() {
        let stage = SegmentWords;
        let ctx = Context::new(JPN);

        let cases = &[
            // Hiragana ‚Üí Hiragana: no break
            ("„Åì„Çì„Å´„Å°„ÅØ", "„Åì„Çì„Å´„Å°„ÅØ"),
            // Hiragana ‚Üí Kanji: no break
            ("„ÅØÊúÄÈ´ò", "„ÅØÊúÄÈ´ò"),
            // Western ‚Üí Hiragana: break
            ("Rust„ÅØ", "Rust „ÅØ"),
            // Western ‚Üí Kanji: break
            ("Hello‰∏ñÁïå", "Hello ‰∏ñÁïå"),
            // ASCII digits ‚Üí Kanji: break
            ("25Âπ¥", "25 Âπ¥"),
            // Mixed Western + Kanji + Hiragana
            ("Êù±‰∫¨2025Âπ¥", "Êù±‰∫¨ 2025 Âπ¥"),
        ];

        for &(input, expected) in cases {
            let output = stage.apply(Cow::Borrowed(input), &ctx).unwrap();
            assert_eq!(output, expected, "Failed on input: {}", input);
        }

        // Extreme/edge cases
        let extremes = &[
            ("", ""),                                         // empty string
            ("A", "A"),                                       // single Western char
            ("‰∏ñ", "‰∏ñ"),                                     // single CJK char
            ("Rust„ÅØ‰∏ñÁïå2025Âπ¥", "Rust „ÅØ‰∏ñÁïå 2025 Âπ¥"),      // long mixed sequence
            ("„ÄÄ„Åì„Çì„Å´„Å°„ÅØ„ÄÄ", "\u{3000}„Åì„Çì„Å´„Å°„ÅØ\u{3000}"), // full-width spaces.
        ];
        for &(input, expected) in extremes {
            let output = stage.apply(Cow::Borrowed(input), &ctx).unwrap();
            assert_eq!(output, expected, "Extreme case failed on input: {}", input);
        }
    }

    // --------------------------- Chinese ---------------------------
    #[test]
    fn test_chinese_segmentation() {
        let stage = SegmentWords;
        let ctx = Context::new(ZHO);

        let cases = &[
            ("Hello‰∏ñÁïå", "Hello ‰∏ñÁïå"), // Western ‚Üí CJK
            ("‰∏ñÁïåHello", "‰∏ñÁïå Hello"), // CJK ‚Üí Western
            ("‰Ω†Â•Ω‰∏ñÁïå", "‰Ω†Â•Ω‰∏ñÁïå"),    // consecutive CJK: no break
        ];

        for &(input, expected) in cases {
            let output = stage.apply(Cow::Borrowed(input), &ctx).unwrap();
            assert_eq!(output, expected, "Failed on input: {}", input);
        }

        // Edge cases
        let extremes = &[
            ("", ""),
            ("A", "A"),
            ("‰∏≠", "‰∏≠"),
            ("Hello‰Ω†Â•ΩWorld‰∏ñÁïå", "Hello ‰Ω†Â•Ω World ‰∏ñÁïå"),
        ];
        for &(input, expected) in extremes {
            let output = stage.apply(Cow::Borrowed(input), &ctx).unwrap();
            assert_eq!(output, expected, "Extreme case failed on input: {}", input);
        }
    }

    // --------------------------- Korean ---------------------------
    #[test]
    fn test_korean_segmentation() {
        let stage = SegmentWords;
        let ctx = Context::new(KOR);

        let cases = &[
            ("HelloÏïàÎÖïÌïòÏÑ∏Ïöî", "Hello ÏïàÎÖïÌïòÏÑ∏Ïöî"), // Western ‚Üí Hangul
            ("ÏïàÎÖïÌïòÏÑ∏ÏöîWorld", "ÏïàÎÖïÌïòÏÑ∏Ïöî World"), // Hangul ‚Üí Western
            ("ÏïàÎÖïÌïòÏÑ∏Ïöî", "ÏïàÎÖïÌïòÏÑ∏Ïöî"),            // Hangul cluster
        ];

        for &(input, expected) in cases {
            let output = stage.apply(Cow::Borrowed(input), &ctx).unwrap();
            assert_eq!(output, expected);
        }

        let extremes = &[
            ("", ""),
            ("Í∞Ä", "Í∞Ä"),                                    // single Hangul
            ("HelloÍ∞ÄWorld", "Hello Í∞Ä World"),              // mixed short
            ("ÏïàÎÖïHelloÏÑ∏ÏÉÅWorld", "ÏïàÎÖï Hello ÏÑ∏ÏÉÅ World"), // longer mixed
        ];
        for &(input, expected) in extremes {
            let output = stage.apply(Cow::Borrowed(input), &ctx).unwrap();
            assert_eq!(output, expected);
        }
    }

    // --------------------------- Thai ---------------------------
    #[test]
    fn test_thai_segmentation() {
        let stage = SegmentWords;
        let ctx = Context::new(THA);

        let cases = &[
            ("Hello‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ", "Hello ‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ"),  // Western ‚Üí Thai
            ("‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µWorld", "‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ World"),  // Thai ‚Üí Western
            ("‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ‡∏ä‡∏≤‡∏ß‡πÇ‡∏•‡∏Å", "‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ‡∏ä‡∏≤‡∏ß‡πÇ‡∏•‡∏Å"), // Thai cluster
        ];

        for &(input, expected) in cases {
            let output = stage.apply(Cow::Borrowed(input), &ctx).unwrap();
            assert_eq!(output, expected);
        }

        let extremes = &[
            ("", ""),
            ("‡∏Å", "‡∏Å"),
            ("Hello‡∏ÅWorld", "Hello ‡∏Å World"),
            ("‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µHello‡∏ä‡∏≤‡∏ß‡πÇ‡∏•‡∏ÅWorld", "‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ Hello ‡∏ä‡∏≤‡∏ß‡πÇ‡∏•‡∏Å World"),
        ];
        for &(input, expected) in extremes {
            let output = stage.apply(Cow::Borrowed(input), &ctx).unwrap();
            assert_eq!(output, expected);
        }
    }

    // --------------------------- Lao ---------------------------
    #[test]
    fn test_lao_segmentation() {
        let stage = SegmentWords;
        let ctx = Context::new(LAO);

        let cases = &[
            ("Hello‡∫™‡∫∞‡∫ö‡∫≤‡∫ç‡∫î‡∫µ", "Hello ‡∫™‡∫∞‡∫ö‡∫≤‡∫ç‡∫î‡∫µ"),
            ("‡∫™‡∫∞‡∫ö‡∫≤‡∫ç‡∫î‡∫µWorld", "‡∫™‡∫∞‡∫ö‡∫≤‡∫ç‡∫î‡∫µ World"),
            ("‡∫™‡∫∞‡∫ö‡∫≤‡∫ç‡∫î‡∫µ‡∫ó‡∫∏‡∫Å‡∫Ñ‡∫ª‡∫ô", "‡∫™‡∫∞‡∫ö‡∫≤‡∫ç‡∫î‡∫µ‡∫ó‡∫∏‡∫Å‡∫Ñ‡∫ª‡∫ô"),
        ];

        for &(input, expected) in cases {
            let output = stage.apply(Cow::Borrowed(input), &ctx).unwrap();
            assert_eq!(output, expected);
        }

        let extremes = &[
            ("", ""),
            ("‡∫Å", "‡∫Å"),
            ("Hello‡∫ÅWorld", "Hello ‡∫Å World"),
            ("‡∫™‡∫∞‡∫ö‡∫≤‡∫çHello‡∫î‡∫µWorld", "‡∫™‡∫∞‡∫ö‡∫≤‡∫ç Hello ‡∫î‡∫µ World"),
        ];
        for &(input, expected) in extremes {
            let output = stage.apply(Cow::Borrowed(input), &ctx).unwrap();
            assert_eq!(output, expected);
        }
    }

    // --------------------------- Myanmar ---------------------------
    #[test]
    fn test_myanmar_segmentation() {
        let stage = SegmentWords;
        let ctx = Context::new(MYA);

        let cases = &[
            ("Hello·Äô·ÄÑ·Ä∫·Äπ·ÄÇ·Äú·Ä¨·Äï·Ä´", "Hello ·Äô·ÄÑ·Ä∫·Äπ·ÄÇ·Äú·Ä¨·Äï·Ä´"),
            ("·Äô·ÄÑ·Ä∫·Äπ·ÄÇ·Äú·Ä¨·Äï·Ä´World", "·Äô·ÄÑ·Ä∫·Äπ·ÄÇ·Äú·Ä¨·Äï·Ä´ World"),
            ("·Äô·ÄÑ·Ä∫·Äπ·ÄÇ·Äú·Ä¨·Äï·Ä´", "·Äô·ÄÑ·Ä∫·Äπ·ÄÇ·Äú·Ä¨·Äï·Ä´"),
        ];

        for &(input, expected) in cases {
            let output = stage.apply(Cow::Borrowed(input), &ctx).unwrap();
            assert_eq!(output, expected);
        }

        let extremes = &[
            ("", ""),
            ("·Äô", "·Äô"),
            ("Hello·ÄôWorld", "Hello ·Äô World"),
            ("·Äô·ÄÑ·Ä∫·Äπ·ÄÇ·Äú·Ä¨Hello·Äï·Ä´World", "·Äô·ÄÑ·Ä∫·Äπ·ÄÇ·Äú·Ä¨ Hello ·Äï·Ä´ World"),
        ];
        for &(input, expected) in extremes {
            let output = stage.apply(Cow::Borrowed(input), &ctx).unwrap();
            assert_eq!(output, expected);
        }
    }

    // --------------------------- Khmer ---------------------------
    #[test]
    fn test_khmer_segmentation() {
        let stage = SegmentWords;
        let ctx = Context::new(KHM);

        let cases = &[
            ("Hello·ûü·ûΩ·ûü·üí·ûè·û∏", "Hello ·ûü·ûΩ·ûü·üí·ûè·û∏"),
            ("·ûü·ûΩ·ûü·üí·ûè·û∏World", "·ûü·ûΩ·ûü·üí·ûè·û∏ World"),
            ("·ûü·ûΩ·ûü·üí·ûè·û∏·ûá·û∂·ûÄ·ûò·üí·ûñ·ûª·ûá·û∂", "·ûü·ûΩ·ûü·üí·ûè·û∏·ûá·û∂·ûÄ·ûò·üí·ûñ·ûª·ûá·û∂"),
        ];

        for &(input, expected) in cases {
            let output = stage.apply(Cow::Borrowed(input), &ctx).unwrap();
            assert_eq!(output, expected);
        }

        let extremes = &[
            ("", ""),
            ("·ûÄ", "·ûÄ"),
            ("Hello·ûÄWorld", "Hello ·ûÄ World"),
            ("·ûü·ûΩ·ûü·üí·ûè·û∏Hello·ûá·û∂·ûÄ·ûò·üí·ûñ·ûª·ûá·û∂World", "·ûü·ûΩ·ûü·üí·ûè·û∏ Hello ·ûá·û∂·ûÄ·ûò·üí·ûñ·ûª·ûá·û∂ World"),
        ];
        for &(input, expected) in extremes {
            let output = stage.apply(Cow::Borrowed(input), &ctx).unwrap();
            assert_eq!(output, expected);
        }
    }

    // Add this to the existing #[cfg(test)] mod in src/stage/segment_words.rs

    #[test]
    fn test_hindi_indic_virama_segmentation() {
        use crate::lang::data::HIN; // Hindi = Devanagari
        use std::borrow::Cow;

        let stage = SegmentWords;
        let ctx = Context::new(HIN);

        // Real-world Hindi examples requiring virama-aware syllable breaks
        let cases = &[
            // "‡§™‡§§‡•ç‡§®‡•Ä" = patnƒ´ ‚Üí ‡§™ + ‡§§ + ‡•ç + ‡§® + ‡•Ä
            // Virama (‡•ç U+094D) joins ‡§§ and ‡§® ‚Üí should insert space *after* virama cluster
            // Expected: "‡§™ ‡§§‡•ç ‡§®‡•Ä" or at minimum "‡§™‡§§‡•ç‡§®‡•Ä" ‚Üí "‡§™ ‡§§‡•ç‡§®‡•Ä" (partial break)
            // Current code: treats all as NonCJKScript ‚Üí no break ‚Üí "‡§™‡§§‡•ç‡§®‡•Ä"
            ("‡§™‡§§‡•ç‡§®‡•Ä", "‡§™ ‡§§‡•ç‡§®‡•Ä"), // Minimal correct: break after virama
            // "‡§∏‡§Ç‡§§‡•ã‡§∑" = sa·πÉto·π£ ‚Üí ‡§∏ + ‡§Ç + ‡§§ + ‡•ã + ‡§∑
            // ‡§®‡•Å‡§ï‡§§‡§æ (‡§Ç U+0902) + consonant cluster
            ("‡§∏‡§Ç‡§§‡•ã‡§∑", "‡§∏‡§Ç ‡§§‡•ã‡§∑"), // Expected: break before ‡§§‡•ã
            // "‡§Ö‡§Ç‡§§‡§∞‡§∞‡§æ‡§∑‡•ç‡§ü‡•ç‡§∞‡•Ä‡§Ø" = antararƒÅ·π£·π≠rƒ´ya
            // Multiple virama clusters: ‡§§‡•ç ‡§∞, ‡§∑‡•ç ‡§ü‡•ç ‡§∞
            ("‡§Ö‡§Ç‡§§‡§∞‡§∞‡§æ‡§∑‡•ç‡§ü‡•ç‡§∞‡•Ä‡§Ø", "‡§Ö‡§®‡•ç‡§§‡§∞‡•ç ‡§∞‡§æ‡§∑‡•ç‡§ü‡•ç‡§∞‡•ç ‡§à‡§Ø"), // Ideal (aggressive)
            // At minimum: should have at least one internal break
            ("‡§Ö‡§Ç‡§§‡§∞‡§∞‡§æ‡§∑‡•ç‡§ü‡•ç‡§∞‡•Ä‡§Ø", "‡§Ö‡§Ç‡§§‡§∞ ‡§∞‡§æ‡§∑‡•ç‡§ü‡•ç‡§∞‡•ç ‡§à‡§Ø"), // Acceptable minimal
            // Mixed script: Hinglish ‚Äî should break on Latin‚ÜîDevanagari AND virama
            ("Hello‡§¶‡•ã‡§∏‡•ç‡§§", "Hello ‡§¶‡•ã‡§∏‡•ç‡§§"),          // Already works
            ("‡§¶‡•ã‡§∏‡•ç‡§§Hello", "‡§¶‡•ã‡§∏‡•ç‡§§ Hello"),          // Already works
            ("‡§Æ‡•á‡§∞‡§æBestFriend", "‡§Æ‡•á‡§∞‡§æ Best Friend"), // Should insert two breaks
            ("‡§Æ‡•á‡§∞‡§æbestfriend", "‡§Æ‡•á‡§∞‡§æ bestfriend"),  // Lowercase: still break
            // Critical: virama at word end (rare but valid in Sanskrit loanwords)
            ("‡§µ‡§ø‡§¶‡•ç‡§µ‡§§‡•ç", "‡§µ‡§ø‡§¶‡•ç‡§µ ‡§§‡•ç"), // "vidvat" (learned) ‚Äî virama-final
        ];

        for &(input, expected) in cases {
            let output = stage.apply(Cow::Borrowed(input), &ctx).unwrap();
            assert_eq!(
                output, expected,
                "\nFAILED: Hindi virama segmentation\n  input:  {input}\n  got:    {output}\n  want:   {expected}\n"
            );
        }

        // Extra assertion: ensure we didn't accidentally break Latin-only text
        let no_break = "hello world";
        let output = stage.apply(Cow::Borrowed(no_break), &ctx).unwrap();
        assert_eq!(
            output, no_break,
            "Should not insert spaces in pure Latin text even under HIN context"
        );
    }

    // Short helper to make ZWSP insertion obvious in test data
    const ZWSP: &str = "\u{200B}";

    #[test]
    fn test_hindi_virama_basic() {
        let stage = SegmentWords;
        let ctx = Context::new(HIN);

        let cases: &[(&str, &str)] = &[
            // single virama joining two consonants -> break AFTER virama
            // ‡§™ + ‡•ç + ‡§§ + ‡•ç + ‡§® + ‡•Ä  => ‡§™‡•ç‚Äå‡§§‡•ç‚Äå‡§®‡•Ä
            ("‡§™‡§§‡•ç‡§®‡•Ä", &format!("‡§™\u{094D}{}‡§§\u{094D}{}‡§®‡•Ä", ZWSP, ZWSP)), // double virama cluster
            // single join: ‡§ï + ‡•ç + ‡§§ -> ‡§ï‡•ç‚Äå‡§§
            ("‡§ï‡•ç‡§µ‡§ø‡§§‡•ç", "‡§ï‡•ç‡§µ‡§ø‡§§‡•ç"), // already has complex cluster; keep as-is if no explicit virama between simple consonants
            // simpler explicit
            ("‡§ï‡•ç‡§§", &format!("‡§ï\u{094D}{}‡§§", ZWSP)),
            // virama followed by vowel sign -> still break after virama if it joins consonant
            ("‡§µ‡§ø‡§ï‡•ç‡§ü‡•ã‡§∞‡§ø‡§Ø‡§æ", &format!("‡§µ‡§ø‡§ï\u{094D}{}‡§ü‡•ã‡§∞‡§ø‡§Ø‡§æ", ZWSP)),
            // word-final virama: no break
            ("‡§µ‡§ø‡§¶‡•ç‡§µ‡§§‡•ç", "‡§µ‡§ø‡§¶‡•ç‡§µ‡§§‡•ç"),
            // ZWJ (U+200D) suppresses virama break
            ("‡§ï‡•ç\u{200D}‡§∑", "‡§ï‡•ç\u{200D}‡§∑"), // virama suppressed by ZWJ -> no ZWSP
            // Nukta (U+093C) combined consonants still obey virama rule
            // (e.g. ‡§ï‡§º = ‡§ï + nukta) followed by virama join
            ("‡§ï‡§º‡•ç‡§§", &format!("‡§ï\u{093C}\u{094D}{}‡§§", ZWSP)),
        ];

        for &(input, expected) in cases {
            let out = stage.apply(Cow::Borrowed(input), &ctx).unwrap();
            assert_eq!(
                out, expected,
                "\nFAILED: Hindi basic\n  input:  {input}\n  got:    {out}\n  want:   {expected}\n"
            );
        }
    }

    #[test]
    fn test_hindi_virama_complex_clusters_and_mixed_script() {
        let stage = SegmentWords;
        let ctx = Context::new(HIN);

        let cases: &[(&str, &str)] = &[
            // long word with multiple viramas -> insert ZWSP after each internal virama (not final)
            (
                "‡§Ö‡§Ç‡§§‡§∞‡§∞‡§æ‡§∑‡•ç‡§ü‡•ç‡§∞‡•Ä‡§Ø",
                // break after ‡§§‡•ç, after ‡§∞‡•ç, after ‡§∑‡•ç, before final vowel cluster as per rule (not word-final)
                &format!(
                    "‡§Ö‡§®‡•ç\u{094D}{}‡§§‡§∞\u{094D}{}‡§∞‡§æ‡§∑\u{094D}{}‡§ü\u{094D}{}‡§∞‡•Ä‡§Ø",
                    ZWSP, ZWSP, ZWSP, ZWSP
                ),
            ),
            // Mixed Hinglish: Devanagari <-> Latin boundaries + virama handling
            ("Hello‡§¶‡•ã‡§∏‡•ç‡§§", &format!("Hello{}‡§¶‡•ã‡§∏‡•ç‡§§", ZWSP)), // script boundary only
            ("‡§Æ‡•á‡§∞‡§æBestFriend", &format!("‡§Æ‡•á‡§∞‡§æ{}Best{}Friend", ZWSP, ZWSP)), // two script boundaries
            ("‡§Æ‡•á‡§∞‡§æbestfriend", &format!("‡§Æ‡•á‡§∞‡§æ{}bestfriend", ZWSP)),
        ];

        for &(input, expected) in cases {
            let out = stage.apply(Cow::Borrowed(input), &ctx).unwrap();
            assert_eq!(
                out, expected,
                "\nFAILED: Hindi complex/mixed\n  input:  {input}\n  got:    {out}\n  want:   {expected}\n"
            );
        }
    }

    #[test]
    fn test_hindi_punctuation_digits_whitespace() {
        let stage = SegmentWords;
        let ctx = Context::new(HIN);

        let cases: &[(&str, &str)] = &[
            // punctuation should cause script<->other boundary as usual
            ("‡§∞‡§æ‡§Æ,‡§∏‡•Ä‡§§‡§æ", &format!("‡§∞‡§æ‡§Æ,{}‡§∏‡•Ä‡§§‡§æ", ZWSP)),
            // digits adjacent to Devanagari -> break
            ("‡§∏‡§æ‡§≤2025", &format!("‡§∏‡§æ‡§≤{}2025", ZWSP)),
            ("2025‡§∏‡§æ‡§≤", &format!("2025{}‡§∏‡§æ‡§≤", ZWSP)),
            // whitespace preserved/collapsed to single ASCII space
            ("  ‡§∞‡§æ‡§Æ   ‡§∏‡•Ä‡§§‡§æ  ", " ‡§∞‡§æ‡§Æ ‡§∏‡•Ä‡§§‡§æ "),
        ];

        for &(input, expected) in cases {
            let out = stage.apply(Cow::Borrowed(input), &ctx).unwrap();
            assert_eq!(
                out, expected,
                "\nFAILED: Hindi punct/digit/whitespace\n  input:  {input}\n  got:    {out}\n  want:   {expected}\n"
            );
        }
    }

    // -------------------- Tamil (pu·∏∑·∏∑i) --------------------

    #[test]
    fn test_tamil_pulli_basic() {
        let stage = SegmentWords;
        let ctx = Context::new(TAM);

        let cases: &[(&str, &str)] = &[
            // pu·∏∑·∏∑i (virama) U+0BCD between consonants -> ZWSP after pu·∏∑·∏∑i (if not word-final)
            ("‡Æ™‡Æ±‡Øç‡Æ±‡Æø", &format!("‡Æ™‡Øç{}‡Æ±‡Øç{}‡Æ±‡Æø", ZWSP, ZWSP)), // double pu·∏∑·∏∑i
            ("‡ÆÖ‡Æï‡Øç‡Æï‡Ææ", &format!("‡ÆÖ‡Æï‡Øç{}‡Æï‡Ææ", ZWSP)),
            ("‡Æá‡Æ≤‡Æô‡Øç‡Æï‡Øà", &format!("‡Æá‡Æ≤‡Æô‡Øç{}‡Æï‡Øà", ZWSP)),
            // no pu·∏∑·∏∑i -> no break
            ("‡Æ§‡ÆÆ‡Æø‡Æ¥‡Øç", "‡Æ§‡ÆÆ‡Æø‡Æ¥‡Øç"),
            // pu·∏∑·∏∑i at word end -> no break
            ("‡Æö‡ÆÆ‡Ææ‡Æ∞‡Øç‡Æ§‡Øç‡Æ§‡Øç\u{0BCD}", "‡Æö‡ÆÆ‡Ææ‡Æ∞‡Øç‡Æ§‡Øç‡Æ§\u{0BCD}"), // final pulli (rare) - no inserted ZWSP
            // ZWJ suppression (Tamil uses ZWJ similarly)
            ("‡Æï‡Øç\u{200D}‡Æï", "‡Æï‡Øç\u{200D}‡Æï"),
        ];

        for &(input, expected) in cases {
            let out = stage.apply(Cow::Borrowed(input), &ctx).unwrap();
            assert_eq!(
                out, expected,
                "\nFAILED: Tamil basic\n  input:  {input}\n  got:    {out}\n  want:   {expected}\n"
            );
        }
    }

    #[test]
    fn test_tamil_complex_and_mixed() {
        let stage = SegmentWords;
        let ctx = Context::new(TAM);

        let cases: &[(&str, &str)] = &[
            // Complex cluster with multiple pu·∏∑·∏∑i -> multiple ZWSP inserted internal
            ("‡Æ™‡Æø‡Æ∞‡Æø‡Æ®‡Øç‡Æ§‡ØÅ‡Æ™‡Øã‡ÆØ‡Æø‡Æ©‡Øç", "‡Æ™‡Æø‡Æ∞‡Æø‡Æ®‡Øç‡Æ§‡ØÅ‡Æ™‡Øã‡ÆØ‡Æø‡Æ©‡Øç"), // no pu·∏∑·∏∑i sequence -> unchanged
            // Mixed Tamil + Latin
            ("Hello‡Æµ‡Æ£‡Æï‡Øç‡Æï‡ÆÆ‡Øç", &format!("Hello{}‡Æµ‡Æ£‡Æï‡Øç‡Æï‡ÆÆ‡Øç", ZWSP)),
            ("‡Æµ‡Æ£‡Æï‡Øç‡Æï‡ÆÆ‡ØçWorld", &format!("‡Æµ‡Æ£‡Æï‡Øç‡Æï‡ÆÆ‡Øç{}World", ZWSP)),
            // digits
            ("‡Æ§‡ÆÆ‡Æø‡Æ¥‡Øç123", &format!("‡Æ§‡ÆÆ‡Æø‡Æ¥‡Øç{}123", ZWSP)),
        ];

        for &(input, expected) in cases {
            let out = stage.apply(Cow::Borrowed(input), &ctx).unwrap();
            assert_eq!(
                out, expected,
                "\nFAILED: Tamil complex/mixed\n  input:  {input}\n  got:    {out}\n  want:   {expected}\n"
            );
        }
    }

    #[test]
    fn test_indic_zwj_and_suppression() {
        let stage = SegmentWords;
        let ctx_h = Context::new(HIN);
        let ctx_t = Context::new(TAM);

        // ZWJ suppresses virama effect (no ZWSP should be inserted)
        let h_input = "‡§ï‡•ç\u{200D}‡§∑"; // Devanagari K + virama + ZWJ + ·π£a
        let h_expected = "‡§ï‡•ç\u{200D}‡§∑";
        let h_out = stage.apply(Cow::Borrowed(h_input), &ctx_h).unwrap();
        assert_eq!(h_out, h_expected, "Hindi ZWJ suppression failed");

        let t_input = "‡Æï‡Øç\u{200D}‡Æï"; // Tamil
        let t_expected = "‡Æï‡Øç\u{200D}‡Æï";
        let t_out = stage.apply(Cow::Borrowed(t_input), &ctx_t).unwrap();
        assert_eq!(t_out, t_expected, "Tamil ZWJ suppression failed");
    }

    #[test]
    fn test_property_no_break_inside_simple_word() {
        let stage = SegmentWords;
        let ctx = Context::new(HIN);

        // Ensure Latin-only text is unchanged under HIN context
        let latin = "hello world";
        let out = stage.apply(Cow::Borrowed(latin), &ctx).unwrap();
        assert_eq!(out, latin, "Should not touch pure Latin text");

        // Ensure single Devanagari word without virama remains unchanged
        let simple = "‡§∞‡§æ‡§Æ‡§æ‡§Ø‡§£";
        let out2 = stage.apply(Cow::Borrowed(simple), &ctx).unwrap();
        assert_eq!(out2, simple, "Should not insert ZWSP when no virama exists");
    }

    // Small helper for iterating character pairs
    fn assert_boundaries(lang: &Lang, pairs: &[(&str, &str)], expected: bool) {
        for &(a, b) in pairs {
            let chars: Vec<char> = a.chars().collect();
            let chars2: Vec<char> = b.chars().collect();
            let lang_entry = LANG_TABLE
                .get(lang.code())
                .copied()
                .expect("language not present in LANG_TABLE ‚Äì this is a bug");
            assert_eq!(
                check_boundary_with_classes(classify(chars[0]), classify(chars2[0]), lang_entry),
                expected,
                "Failed: {} -> {} for {}",
                a,
                b,
                std::any::type_name::<Lang>()
            );
        }
    }

    #[test]
    fn test_whitespace_no_boundary() {
        let whitespace_pairs = &[(" ", "„ÅÇ"), ("„ÅÇ", " "), ("\n", "A"), ("A", "\t")];
        assert_boundaries(&JPN, whitespace_pairs, false);
    }

    #[test]
    fn test_western_script_breaks() {
        let pairs = &[
            ("A", "„ÅÇ"),
            ("„ÅÇ", "A"),
            ("A", "‰∏≠"),
            ("Êñá", "A"),
            ("A", "\u{AC00}"), // Hangul
            ("\u{AC00}", "A"),
        ];
        assert_boundaries(&JPN, &pairs[0..2], true);
        assert_boundaries(&ZHO, &pairs[2..4], true);
        assert_boundaries(&KOR, &pairs[4..6], true);
    }

    #[test]
    fn test_same_cluster_no_break() {
        let japanese = &[("„ÅÇ", "„Ç¢")];
        let hangul = &[("\u{AC00}", "\u{AC01}")];
        let thai = &[("\u{0E01}", "\u{0E02}")];

        assert_boundaries(&JPN, japanese, false);
        assert_boundaries(&KOR, hangul, false);
        assert_boundaries(&THA, thai, false);
    }

    #[test]
    fn test_punctuation_and_symbols() {
        let script_to_punct = &[
            ("Êó•", ")"),
            ("Êñá", "."),
            ("\u{0E01}", ","),
            ("\u{AC00}", "-"),
        ];
        let script_to_emoji = &[("„ÅÇ", "üòÄ"), ("üòÄ", "„ÅÇ"), ("A", "üòÉ"), ("Í∞Ä", "üéâ")];

        assert_boundaries(&JPN, &script_to_punct[0..2], true);
        assert_boundaries(&THA, &script_to_punct[2..3], true);
        assert_boundaries(&KOR, &script_to_punct[3..4], true);

        assert_boundaries(&JPN, &script_to_emoji[0..2], true);
        assert_boundaries(&ZHO, &script_to_emoji[2..3], true);
        assert_boundaries(&KOR, &script_to_emoji[3..4], true);
    }

    #[test]
    fn test_digits_break() {
        let pairs = &[("1", "„ÅÇ"), ("„ÅÇ", "1"), ("9", "‰∏≠"), ("0", "\u{AC00}")];
        assert_boundaries(&JPN, &pairs[0..2], true);
        assert_boundaries(&ZHO, &pairs[2..3], true);
        assert_boundaries(&KOR, &pairs[3..4], true);
    }

    #[test]
    fn test_cross_script_clusters() {
        let pairs = &[
            ("A", "–Ø"),
            ("Z", "–ñ"),
            ("„ÅÇ", "\u{0E01}"),
            ("Êñá", "\u{AC00}"),
        ];
        assert_boundaries(&JPN, &pairs[0..3], true);
        assert_boundaries(&KOR, &pairs[1..4], true);
    }

    #[test]
    fn test_edge_cjk_blocks() {
        // No break inside CJK blocks
        let no_break = &[("\u{2F00}", "\u{2F01}"), ("\u{2F00}", "\u{2F00}")];
        assert_boundaries(&JPN, no_break, false);

        // Break with CJK punctuation
        let break_pairs = &[("„ÄÅ", "„ÅÇ"), ("Êó•", "„ÄÇ")];
        assert_boundaries(&JPN, break_pairs, true);
    }

    #[test]
    fn test_western_and_digits() {
        let pairs = &[
            ("A", "B"), // Western ‚Üí Western
            ("1", "2"), // Digit ‚Üí Digit
            ("A", "1"), // Letter ‚Üí Digit
            ("1", "A"), // Digit ‚Üí Letter
        ];
        assert_boundaries(&JPN, &pairs[0..2], false); // Western‚ÜíWestern and digits: no break
        assert_boundaries(&JPN, &pairs[2..4], false); // Cross Western class: no break
    }

    #[test]
    fn test_ascii_to_cjk_and_back() {
        let pairs = &[
            ("H", "‰∏ñ"), // Western ‚Üí CJK
            ("o", "‰∏ñ"), // Western ‚Üí CJK
            ("‰∏ñ", "H"), // CJK ‚Üí Western
            ("Êñá", "A"), // CJK ‚Üí Western
        ];
        // Western -> CJK: MUST insert space (true)
        assert_boundaries(&JPN, &pairs[0..2], true);

        // CJK -> Western: MUST insert space (true)
        assert_boundaries(&JPN, &pairs[2..4], true); // <-- FIX: Change false to true
    }
}
