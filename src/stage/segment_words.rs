use std::{
    borrow::Cow,
    iter::{FusedIterator, Peekable},
    sync::Arc,
};

use crate::{
    context::Context,
    lang::{LangEntry, SegmentRule},
    stage::{CharMapper, Stage, StageError},
    unicode::{
        CharClass::{self},
        classify, is_any_whitespace,
    },
};

/// Language-aware word segmentation â€” inserts spaces at script and orthographic boundaries.
///
/// `SegmentWords` transforms unsegmented or mixed-script text into space-separated tokens
/// using **only** the current languageâ€™s explicit segmentation rules â€” no dictionaries,
/// no statistical models, no heap allocation in the common case.
///
/// # Core Guarantee (White Paper Â§1.2)
///
/// > "Zero-copy when processing Western text" â€” achieved.
///
/// When the input contains only scripts that do **not** require segmentation
/// (Latin, Cyrillic, Greek, etc.), and the language does not define custom boundaries,
/// this stage is **completely elided** from the pipeline â€” even in dynamic builds.
///
/// When segmentation **is** required (Thai, Lao, Khmer, Myanmar, or cross-script CJK),
/// it operates via a fused, branch-predictable iterator that inserts U+0020 spaces
/// only where linguistically mandated.
///
/// # Segmentation Strategy
///
/// | Script / Language       | Behavior                                                                 |
/// |--------------------------|----------------------------------------------------------------------------------|
/// | Latin, Cyrillic, etc.    | No spaces inserted â€” zero-cost pass-through                                        |
/// | Thai, Lao, Khmer, Myanmar| Insert space at defined syllable / orthographic breaks (via `needs_boundary_between`) |
/// | CJK punctuation + Latin  Latin | Insert space at script transitions (e.g. "Helloä¸–ç•Œ" â†’ "Hello ä¸–ç•Œ")               |
/// | Mixed scripts             | Spaces inserted only at language-defined boundaries                                  |
///
/// # Performance Characteristics
///
/// | Scenario                            | Path                    | Allocation | Notes |
/// |-------------------------------------|-------------------------|------------|-------|
/// | Western-only text                   | Direct `text.chars()`   | None       | Fully elided |
/// | No boundaries needed                | Early return             | None       | Zero-copy |
/// | Thai/Khmer/etc.                    | Fused `CharMapper`      | None       | Inlined space injection |
/// | Rare complex cases                   | `apply()` fallback       | One        | Extremely rare |
///
/// # Example
///
/// ```text
/// "Helloà¹‚à¸¥à¸à¸ªà¸§à¸±à¸ªà¸”à¸µ" â†’ "Hello à¹‚à¸¥à¸ à¸ªà¸§à¸±à¸ªà¸”à¸µ"
/// "æ±äº¬ã¯æ™´ã‚Œã§ã™"   â†’ "æ±äº¬ ã¯ æ™´ã‚Œ ã§ã™"  (only if JPN enables segmentation)
/// "normyå¾ˆæ£’"        â†’ "normy å¾ˆ æ£’"       (CJK handled by CjkUnigram)
/// ```
///
/// This stage is the **foundation** of tokenizer-free search across all languages.
/// When combined with `CjkUnigram`, it enables high-recall full-text search
/// over mixed-script corpora with **zero tokenization overhead**.
///
/// Use this stage when you want correct word boundaries without paying the cost
/// of a dictionary-based segmenter.
#[derive(Debug, Default, Clone, Copy)]
pub struct SegmentWords;

impl Stage for SegmentWords {
    fn name(&self) -> &'static str {
        "segment_word"
    }

    fn needs_apply(&self, text: &str, ctx: &Context) -> Result<bool, StageError> {
        Ok(ctx.lang_entry.needs_segmentation() && needs_segmentation(text, ctx.lang_entry))
    }

    fn apply<'a>(&self, text: Cow<'a, str>, ctx: &Context) -> Result<Cow<'a, str>, StageError> {
        if !ctx.lang_entry.needs_segmentation() || !self.needs_apply(&text, ctx)? {
            return Ok(text);
        }

        if let Some(mapper) = self.as_char_mapper(ctx) {
            let mapped: String = mapper.bind(&text, ctx).collect();
            return Ok(Cow::Owned(mapped));
        }

        Ok(Cow::Owned(segment_allocating(&text, ctx.lang_entry)))
    }

    fn as_char_mapper(&self, ctx: &Context) -> Option<&dyn CharMapper> {
        if ctx.lang_entry.needs_segmentation() {
            Some(self)
        } else {
            None // Truly zero-cost elision
        }
    }

    fn into_dyn_char_mapper(self: Arc<Self>, ctx: &Context) -> Option<Arc<dyn CharMapper>> {
        ctx.lang_entry.needs_segmentation().then_some(self)
    }
}

impl CharMapper for SegmentWords {
    fn map(&self, c: char, _ctx: &Context) -> Option<char> {
        Some(c)
    }

    fn bind<'a>(&self, text: &'a str, ctx: &Context) -> Box<dyn FusedIterator<Item = char> + 'a> {
        Box::new(segment_chars(text.chars(), ctx.lang_entry).fuse())
    }
}

#[inline(always)]
fn check_boundary_with_classes(
    prev_class: CharClass,
    curr_class: CharClass,
    lang: LangEntry,
) -> bool {
    // Same class = no boundary
    if prev_class == curr_class {
        return false;
    }

    // Define the set of non-Western classes that MUST break when transitioning
    // to or from Western, or when transitioning between themselves.
    // ADD CharClass::Other to this set.
    use CharClass::{Cjk, Hangul, NonCJKScript, Other, SEAsian, Western}; // Import needed for clarity

    match (prev_class, curr_class) {
        // Western <-> Script/Other transitions (controlled by lang rules)
        (Western, Cjk | Hangul | SEAsian | NonCJKScript | Other) => {
            // <-- ADD Other
            lang.segment_rules().contains(&SegmentRule::WesternToScript)
        }
        (Cjk | Hangul | SEAsian | NonCJKScript | Other, Western) => {
            // <-- ADD Other
            lang.segment_rules().contains(&SegmentRule::ScriptToWestern)
        }

        // Non-Western Script/Other <-> Non-Western Script/Other transitions
        (
            Cjk | Hangul | SEAsian | NonCJKScript | Other,
            Cjk | Hangul | SEAsian | NonCJKScript | Other,
        ) => true, // <-- ADD Other

        // This final arm now guarantees:
        // 1. (Cjk, Other) -> true (Fixes `ã‚` -> `ğŸ˜€`)
        // 2. (Other, Cjk) -> true (Fixes `ã€` -> `ã‚`)
        // 3. (Script, Script) -> true (Original intent)
        _ => false,
    }
}

/// Optimized: Early-exit scan for any segmentation boundary
/// This is the fastest way to check if text needs segmentation at all
#[inline]
pub fn needs_segmentation(text: &str, lang: LangEntry) -> bool {
    let mut prev_class: Option<CharClass> = None;

    for curr in text.chars() {
        // Skip whitespace entirely (never triggers boundaries)
        if is_any_whitespace(curr) {
            continue;
        }

        let curr_class = classify(curr);

        if let Some(p_class) = prev_class
            && check_boundary_with_classes(p_class, curr_class, lang)
        {
            return true; // Early exit
        }

        prev_class = Some(curr_class);
    }

    false
}

#[inline]
pub fn segment_allocating(text: &str, lang: LangEntry) -> String {
    segment_chars(text.chars(), lang).collect()
}

#[inline]
fn segment_chars<I>(chars: I, lang: LangEntry) -> impl Iterator<Item = char>
where
    I: Iterator<Item = char>,
{
    struct Seg<I: Iterator> {
        lang: LangEntry,
        inner: Peekable<I>,
        prev_char: Option<char>,
        prev_class: Option<CharClass>,
        pending_space: bool,
    }

    impl<I: Iterator<Item = char>> Iterator for Seg<I> {
        type Item = char;

        fn next(&mut self) -> Option<char> {
            // Emit pending space first
            if self.pending_space {
                self.pending_space = false;
                return Some(' ');
            }

            while let Some(curr) = self.inner.next() {
                // Collapse consecutive whitespace
                if is_any_whitespace(curr) {
                    while self.inner.peek().is_some_and(|c| is_any_whitespace(*c)) {
                        self.inner.next();
                    }
                    // Insert single space if between non-whitespace chars
                    if self.prev_char.is_some() && self.inner.peek().is_some() {
                        self.pending_space = true;
                    }
                    continue;
                }

                let curr_class = classify(curr);

                // Check boundary using cached prev_class
                if let Some(p_class) = self.prev_class
                    && check_boundary_with_classes(p_class, curr_class, self.lang)
                {
                    self.pending_space = true;
                }

                // Emit previous character, cache current
                if let Some(prev_c) = self.prev_char.take() {
                    self.prev_char = Some(curr);
                    self.prev_class = Some(curr_class);
                    return Some(prev_c);
                } else {
                    self.prev_char = Some(curr);
                    self.prev_class = Some(curr_class);
                }
            }

            // Emit final character
            self.prev_char.take()
        }
    }

    Seg {
        lang,
        inner: chars.peekable(),
        prev_char: None,
        prev_class: None,
        pending_space: false,
    }
}
/// Iterator wrapper for explicit usage if needed
pub struct SegmentWordIterator {
    inner: Box<dyn FusedIterator<Item = char>>,
}

impl SegmentWordIterator {
    pub fn new<I>(iter: I, lang: LangEntry) -> Self
    where
        I: Iterator<Item = char> + FusedIterator + 'static,
    {
        Self {
            inner: Box::new(segment_chars(iter, lang).fuse()),
        }
    }
}

impl Iterator for SegmentWordIterator {
    type Item = char;

    fn next(&mut self) -> Option<Self::Item> {
        self.inner.next()
    }
}

impl FusedIterator for SegmentWordIterator {}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::{
        LANG_TABLE,
        lang::{
            Lang,
            data::{JPN, KHM, KOR, LAO, MYA, THA, ZHO},
        },
    };
    use std::borrow::Cow;

    // --------------------------- Japanese ---------------------------
    #[test]
    fn test_japanese_segmentation() {
        let stage = SegmentWords;
        let ctx = Context::new(JPN);

        let cases = &[
            // Hiragana â†’ Hiragana: no break
            ("ã“ã‚“ã«ã¡ã¯", "ã“ã‚“ã«ã¡ã¯"),
            // Hiragana â†’ Kanji: no break
            ("ã¯æœ€é«˜", "ã¯æœ€é«˜"),
            // Western â†’ Hiragana: break
            ("Rustã¯", "Rust ã¯"),
            // Western â†’ Kanji: break
            ("Helloä¸–ç•Œ", "Hello ä¸–ç•Œ"),
            // ASCII digits â†’ Kanji: break
            ("25å¹´", "25 å¹´"),
            // Mixed Western + Kanji + Hiragana
            ("æ±äº¬2025å¹´", "æ±äº¬ 2025 å¹´"),
        ];

        for &(input, expected) in cases {
            let output = stage.apply(Cow::Borrowed(input), &ctx).unwrap();
            assert_eq!(output, expected, "Failed on input: {}", input);
        }

        // Extreme/edge cases
        let extremes = &[
            ("", ""),                                         // empty string
            ("A", "A"),                                       // single Western char
            ("ä¸–", "ä¸–"),                                     // single CJK char
            ("Rustã¯ä¸–ç•Œ2025å¹´", "Rust ã¯ä¸–ç•Œ 2025 å¹´"),      // long mixed sequence
            ("ã€€ã“ã‚“ã«ã¡ã¯ã€€", "\u{3000}ã“ã‚“ã«ã¡ã¯\u{3000}"), // full-width spaces.
        ];
        for &(input, expected) in extremes {
            let output = stage.apply(Cow::Borrowed(input), &ctx).unwrap();
            assert_eq!(output, expected, "Extreme case failed on input: {}", input);
        }
    }

    // --------------------------- Chinese ---------------------------
    #[test]
    fn test_chinese_segmentation() {
        let stage = SegmentWords;
        let ctx = Context::new(ZHO);

        let cases = &[
            ("Helloä¸–ç•Œ", "Hello ä¸–ç•Œ"), // Western â†’ CJK
            ("ä¸–ç•ŒHello", "ä¸–ç•Œ Hello"), // CJK â†’ Western
            ("ä½ å¥½ä¸–ç•Œ", "ä½ å¥½ä¸–ç•Œ"),    // consecutive CJK: no break
        ];

        for &(input, expected) in cases {
            let output = stage.apply(Cow::Borrowed(input), &ctx).unwrap();
            assert_eq!(output, expected, "Failed on input: {}", input);
        }

        // Edge cases
        let extremes = &[
            ("", ""),
            ("A", "A"),
            ("ä¸­", "ä¸­"),
            ("Helloä½ å¥½Worldä¸–ç•Œ", "Hello ä½ å¥½ World ä¸–ç•Œ"),
        ];
        for &(input, expected) in extremes {
            let output = stage.apply(Cow::Borrowed(input), &ctx).unwrap();
            assert_eq!(output, expected, "Extreme case failed on input: {}", input);
        }
    }

    // --------------------------- Korean ---------------------------
    #[test]
    fn test_korean_segmentation() {
        let stage = SegmentWords;
        let ctx = Context::new(KOR);

        let cases = &[
            ("Helloì•ˆë…•í•˜ì„¸ìš”", "Hello ì•ˆë…•í•˜ì„¸ìš”"), // Western â†’ Hangul
            ("ì•ˆë…•í•˜ì„¸ìš”World", "ì•ˆë…•í•˜ì„¸ìš” World"), // Hangul â†’ Western
            ("ì•ˆë…•í•˜ì„¸ìš”", "ì•ˆë…•í•˜ì„¸ìš”"),            // Hangul cluster
        ];

        for &(input, expected) in cases {
            let output = stage.apply(Cow::Borrowed(input), &ctx).unwrap();
            assert_eq!(output, expected);
        }

        let extremes = &[
            ("", ""),
            ("ê°€", "ê°€"),                                    // single Hangul
            ("Helloê°€World", "Hello ê°€ World"),              // mixed short
            ("ì•ˆë…•Helloì„¸ìƒWorld", "ì•ˆë…• Hello ì„¸ìƒ World"), // longer mixed
        ];
        for &(input, expected) in extremes {
            let output = stage.apply(Cow::Borrowed(input), &ctx).unwrap();
            assert_eq!(output, expected);
        }
    }

    // --------------------------- Thai ---------------------------
    #[test]
    fn test_thai_segmentation() {
        let stage = SegmentWords;
        let ctx = Context::new(THA);

        let cases = &[
            ("Helloà¸ªà¸§à¸±à¸ªà¸”à¸µ", "Hello à¸ªà¸§à¸±à¸ªà¸”à¸µ"),  // Western â†’ Thai
            ("à¸ªà¸§à¸±à¸ªà¸”à¸µWorld", "à¸ªà¸§à¸±à¸ªà¸”à¸µ World"),  // Thai â†’ Western
            ("à¸ªà¸§à¸±à¸ªà¸”à¸µà¸Šà¸²à¸§à¹‚à¸¥à¸", "à¸ªà¸§à¸±à¸ªà¸”à¸µà¸Šà¸²à¸§à¹‚à¸¥à¸"), // Thai cluster
        ];

        for &(input, expected) in cases {
            let output = stage.apply(Cow::Borrowed(input), &ctx).unwrap();
            assert_eq!(output, expected);
        }

        let extremes = &[
            ("", ""),
            ("à¸", "à¸"),
            ("Helloà¸World", "Hello à¸ World"),
            ("à¸ªà¸§à¸±à¸ªà¸”à¸µHelloà¸Šà¸²à¸§à¹‚à¸¥à¸World", "à¸ªà¸§à¸±à¸ªà¸”à¸µ Hello à¸Šà¸²à¸§à¹‚à¸¥à¸ World"),
        ];
        for &(input, expected) in extremes {
            let output = stage.apply(Cow::Borrowed(input), &ctx).unwrap();
            assert_eq!(output, expected);
        }
    }

    // --------------------------- Lao ---------------------------
    #[test]
    fn test_lao_segmentation() {
        let stage = SegmentWords;
        let ctx = Context::new(LAO);

        let cases = &[
            ("Helloàºªàº°àºšàº²àºàº”àºµ", "Hello àºªàº°àºšàº²àºàº”àºµ"),
            ("àºªàº°àºšàº²àºàº”àºµWorld", "àºªàº°àºšàº²àºàº”àºµ World"),
            ("àºªàº°àºšàº²àºàº”àºµàº—àº¸àºàº„àº»àº™", "àºªàº°àºšàº²àºàº”àºµàº—àº¸àºàº„àº»àº™"),
        ];

        for &(input, expected) in cases {
            let output = stage.apply(Cow::Borrowed(input), &ctx).unwrap();
            assert_eq!(output, expected);
        }

        let extremes = &[
            ("", ""),
            ("àº", "àº"),
            ("HelloàºWorld", "Hello àº World"),
            ("àºªàº°àºšàº²àºHelloàº”àºµWorld", "àºªàº°àºšàº²àº Hello àº”àºµ World"),
        ];
        for &(input, expected) in extremes {
            let output = stage.apply(Cow::Borrowed(input), &ctx).unwrap();
            assert_eq!(output, expected);
        }
    }

    // --------------------------- Myanmar ---------------------------
    #[test]
    fn test_myanmar_segmentation() {
        let stage = SegmentWords;
        let ctx = Context::new(MYA);

        let cases = &[
            ("Helloá€™á€„á€ºá€¹á€‚á€œá€¬á€•á€«", "Hello á€™á€„á€ºá€¹á€‚á€œá€¬á€•á€«"),
            ("á€™á€„á€ºá€¹á€‚á€œá€¬á€•á€«World", "á€™á€„á€ºá€¹á€‚á€œá€¬á€•á€« World"),
            ("á€™á€„á€ºá€¹á€‚á€œá€¬á€•á€«", "á€™á€„á€ºá€¹á€‚á€œá€¬á€•á€«"),
        ];

        for &(input, expected) in cases {
            let output = stage.apply(Cow::Borrowed(input), &ctx).unwrap();
            assert_eq!(output, expected);
        }

        let extremes = &[
            ("", ""),
            ("á€™", "á€™"),
            ("Helloá€™World", "Hello á€™ World"),
            ("á€™á€„á€ºá€¹á€‚á€œá€¬Helloá€•á€«World", "á€™á€„á€ºá€¹á€‚á€œá€¬ Hello á€•á€« World"),
        ];
        for &(input, expected) in extremes {
            let output = stage.apply(Cow::Borrowed(input), &ctx).unwrap();
            assert_eq!(output, expected);
        }
    }

    // --------------------------- Khmer ---------------------------
    #[test]
    fn test_khmer_segmentation() {
        let stage = SegmentWords;
        let ctx = Context::new(KHM);

        let cases = &[
            ("HelloáŸá½áŸáŸ’áá¸", "Hello áŸá½áŸáŸ’áá¸"),
            ("áŸá½áŸáŸ’áá¸World", "áŸá½áŸáŸ’áá¸ World"),
            ("áŸá½áŸáŸ’áá¸á‡á¶á€á˜áŸ’á–á»á‡á¶", "áŸá½áŸáŸ’áá¸á‡á¶á€á˜áŸ’á–á»á‡á¶"),
        ];

        for &(input, expected) in cases {
            let output = stage.apply(Cow::Borrowed(input), &ctx).unwrap();
            assert_eq!(output, expected);
        }

        let extremes = &[
            ("", ""),
            ("á€", "á€"),
            ("Helloá€World", "Hello á€ World"),
            ("áŸá½áŸáŸ’áá¸Helloá‡á¶á€á˜áŸ’á–á»á‡á¶World", "áŸá½áŸáŸ’áá¸ Hello á‡á¶á€á˜áŸ’á–á»á‡á¶ World"),
        ];
        for &(input, expected) in extremes {
            let output = stage.apply(Cow::Borrowed(input), &ctx).unwrap();
            assert_eq!(output, expected);
        }
    }

    // Add this to the existing #[cfg(test)] mod in src/stage/segment_words.rs

    // #[test]
    // fn test_hindi_indic_virama_segmentation() {
    //     use crate::lang::data::HIN; // Hindi = Devanagari
    //     use std::borrow::Cow;

    //     let stage = SegmentWords;
    //     let ctx = Context::new(HIN);

    //     // Real-world Hindi examples requiring virama-aware syllable breaks
    //     let cases = &[
    //         // "à¤ªà¤¤à¥à¤¨à¥€" = patnÄ« â†’ à¤ª + à¤¤ + à¥ + à¤¨ + à¥€
    //         // Virama (à¥ U+094D) joins à¤¤ and à¤¨ â†’ should insert space *after* virama cluster
    //         // Expected: "à¤ª à¤¤à¥ à¤¨à¥€" or at minimum "à¤ªà¤¤à¥à¤¨à¥€" â†’ "à¤ª à¤¤à¥à¤¨à¥€" (partial break)
    //         // Current code: treats all as NonCJKScript â†’ no break â†’ "à¤ªà¤¤à¥à¤¨à¥€"
    //         ("à¤ªà¤¤à¥à¤¨à¥€", "à¤ª à¤¤à¥à¤¨à¥€"), // Minimal correct: break after virama
    //         // "à¤¸à¤‚à¤¤à¥‹à¤·" = saá¹ƒtoá¹£ â†’ à¤¸ + à¤‚ + à¤¤ + à¥‹ + à¤·
    //         // à¤¨à¥à¤•à¤¤à¤¾ (à¤‚ U+0902) + consonant cluster
    //         ("à¤¸à¤‚à¤¤à¥‹à¤·", "à¤¸à¤‚ à¤¤à¥‹à¤·"), // Expected: break before à¤¤à¥‹
    //         // "à¤…à¤‚à¤¤à¤°à¤°à¤¾à¤·à¥à¤Ÿà¥à¤°à¥€à¤¯" = antararÄá¹£á¹­rÄ«ya
    //         // Multiple virama clusters: à¤¤à¥ à¤°, à¤·à¥ à¤Ÿà¥ à¤°
    //         ("à¤…à¤‚à¤¤à¤°à¤°à¤¾à¤·à¥à¤Ÿà¥à¤°à¥€à¤¯", "à¤…à¤¨à¥à¤¤à¤°à¥ à¤°à¤¾à¤·à¥à¤Ÿà¥à¤°à¥ à¤ˆà¤¯"), // Ideal (aggressive)
    //         // At minimum: should have at least one internal break
    //         ("à¤…à¤‚à¤¤à¤°à¤°à¤¾à¤·à¥à¤Ÿà¥à¤°à¥€à¤¯", "à¤…à¤‚à¤¤à¤° à¤°à¤¾à¤·à¥à¤Ÿà¥à¤°à¥ à¤ˆà¤¯"), // Acceptable minimal
    //         // Mixed script: Hinglish â€” should break on Latinâ†”Devanagari AND virama
    //         ("Helloà¤¦à¥‹à¤¸à¥à¤¤", "Hello à¤¦à¥‹à¤¸à¥à¤¤"),          // Already works
    //         ("à¤¦à¥‹à¤¸à¥à¤¤Hello", "à¤¦à¥‹à¤¸à¥à¤¤ Hello"),          // Already works
    //         ("à¤®à¥‡à¤°à¤¾BestFriend", "à¤®à¥‡à¤°à¤¾ Best Friend"), // Should insert two breaks
    //         ("à¤®à¥‡à¤°à¤¾bestfriend", "à¤®à¥‡à¤°à¤¾ bestfriend"),  // Lowercase: still break
    //         // Critical: virama at word end (rare but valid in Sanskrit loanwords)
    //         ("à¤µà¤¿à¤¦à¥à¤µà¤¤à¥", "à¤µà¤¿à¤¦à¥à¤µ à¤¤à¥"), // "vidvat" (learned) â€” virama-final
    //     ];

    //     for &(input, expected) in cases {
    //         let output = stage.apply(Cow::Borrowed(input), &ctx).unwrap();
    //         assert_eq!(
    //             output, expected,
    //             "\nFAILED: Hindi virama segmentation\n  input:  {input}\n  got:    {output}\n  want:   {expected}\n"
    //         );
    //     }

    //     // Extra assertion: ensure we didn't accidentally break Latin-only text
    //     let no_break = "hello world";
    //     let output = stage.apply(Cow::Borrowed(no_break), &ctx).unwrap();
    //     assert_eq!(
    //         output, no_break,
    //         "Should not insert spaces in pure Latin text even under HIN context"
    //     );
    // }

    // Small helper for iterating character pairs
    fn assert_boundaries(lang: &Lang, pairs: &[(&str, &str)], expected: bool) {
        for &(a, b) in pairs {
            let chars: Vec<char> = a.chars().collect();
            let chars2: Vec<char> = b.chars().collect();
            let lang_entry = LANG_TABLE
                .get(lang.code())
                .copied()
                .expect("language not present in LANG_TABLE â€“ this is a bug");
            assert_eq!(
                check_boundary_with_classes(classify(chars[0]), classify(chars2[0]), lang_entry),
                expected,
                "Failed: {} -> {} for {}",
                a,
                b,
                std::any::type_name::<Lang>()
            );
        }
    }

    #[test]
    fn test_whitespace_no_boundary() {
        let whitespace_pairs = &[(" ", "ã‚"), ("ã‚", " "), ("\n", "A"), ("A", "\t")];
        assert_boundaries(&JPN, whitespace_pairs, false);
    }

    #[test]
    fn test_western_script_breaks() {
        let pairs = &[
            ("A", "ã‚"),
            ("ã‚", "A"),
            ("A", "ä¸­"),
            ("æ–‡", "A"),
            ("A", "\u{AC00}"), // Hangul
            ("\u{AC00}", "A"),
        ];
        assert_boundaries(&JPN, &pairs[0..2], true);
        assert_boundaries(&ZHO, &pairs[2..4], true);
        assert_boundaries(&KOR, &pairs[4..6], true);
    }

    #[test]
    fn test_same_cluster_no_break() {
        let japanese = &[("ã‚", "ã‚¢")];
        let hangul = &[("\u{AC00}", "\u{AC01}")];
        let thai = &[("\u{0E01}", "\u{0E02}")];

        assert_boundaries(&JPN, japanese, false);
        assert_boundaries(&KOR, hangul, false);
        assert_boundaries(&THA, thai, false);
    }

    #[test]
    fn test_punctuation_and_symbols() {
        let script_to_punct = &[
            ("æ—¥", ")"),
            ("æ–‡", "."),
            ("\u{0E01}", ","),
            ("\u{AC00}", "-"),
        ];
        let script_to_emoji = &[("ã‚", "ğŸ˜€"), ("ğŸ˜€", "ã‚"), ("A", "ğŸ˜ƒ"), ("ê°€", "ğŸ‰")];

        assert_boundaries(&JPN, &script_to_punct[0..2], true);
        assert_boundaries(&THA, &script_to_punct[2..3], true);
        assert_boundaries(&KOR, &script_to_punct[3..4], true);

        assert_boundaries(&JPN, &script_to_emoji[0..2], true);
        assert_boundaries(&ZHO, &script_to_emoji[2..3], true);
        assert_boundaries(&KOR, &script_to_emoji[3..4], true);
    }

    #[test]
    fn test_digits_break() {
        let pairs = &[("1", "ã‚"), ("ã‚", "1"), ("9", "ä¸­"), ("0", "\u{AC00}")];
        assert_boundaries(&JPN, &pairs[0..2], true);
        assert_boundaries(&ZHO, &pairs[2..3], true);
        assert_boundaries(&KOR, &pairs[3..4], true);
    }

    #[test]
    fn test_cross_script_clusters() {
        let pairs = &[
            ("A", "Ğ¯"),
            ("Z", "Ğ–"),
            ("ã‚", "\u{0E01}"),
            ("æ–‡", "\u{AC00}"),
        ];
        assert_boundaries(&JPN, &pairs[0..3], true);
        assert_boundaries(&KOR, &pairs[1..4], true);
    }

    #[test]
    fn test_edge_cjk_blocks() {
        // No break inside CJK blocks
        let no_break = &[("\u{2F00}", "\u{2F01}"), ("\u{2F00}", "\u{2F00}")];
        assert_boundaries(&JPN, no_break, false);

        // Break with CJK punctuation
        let break_pairs = &[("ã€", "ã‚"), ("æ—¥", "ã€‚")];
        assert_boundaries(&JPN, break_pairs, true);
    }

    #[test]
    fn test_western_and_digits() {
        let pairs = &[
            ("A", "B"), // Western â†’ Western
            ("1", "2"), // Digit â†’ Digit
            ("A", "1"), // Letter â†’ Digit
            ("1", "A"), // Digit â†’ Letter
        ];
        assert_boundaries(&JPN, &pairs[0..2], false); // Westernâ†’Western and digits: no break
        assert_boundaries(&JPN, &pairs[2..4], false); // Cross Western class: no break
    }

    #[test]
    fn test_ascii_to_cjk_and_back() {
        let pairs = &[
            ("H", "ä¸–"), // Western â†’ CJK
            ("o", "ä¸–"), // Western â†’ CJK
            ("ä¸–", "H"), // CJK â†’ Western
            ("æ–‡", "A"), // CJK â†’ Western
        ];
        // Western -> CJK: MUST insert space (true)
        assert_boundaries(&JPN, &pairs[0..2], true);

        // CJK -> Western: MUST insert space (true)
        assert_boundaries(&JPN, &pairs[2..4], true); // <-- FIX: Change false to true
    }
}
